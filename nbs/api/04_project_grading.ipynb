{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38120b0d",
   "metadata": {},
   "source": [
    "# Project Grading\n",
    "\n",
    "> Manage grading rubrics and grade posting on the groups grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b542387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from CanvasGroupy.github import GitHubGroup\n",
    "from CanvasGroupy.canvas import CanvasGroup\n",
    "import github\n",
    "import canvasapi\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Grading:\n",
    "    def __init__(self,\n",
    "                 ghg=None, # authenticated GitHub object\n",
    "                 cg=None, # authenticated canvas object\n",
    "                ):\n",
    "        self.ghg = ghg\n",
    "        self.cg = cg\n",
    "\n",
    "    def create_issue_from_md(self,\n",
    "                              repo:github.Repository.Repository, # target repository to create issue\n",
    "                              md_fp: str # file path of the feedback markdown file\n",
    "                              ) -> github.Issue.Issue: # open issue\n",
    "        \"Create GitHub issue from markdown file.\"\n",
    "        return self.ghg.create_issue_from_md(repo, md_fp)\n",
    "\n",
    "    def fetch_issue(self,\n",
    "                    repo:github.Repository.Repository, # target repository to fetch issue\n",
    "                    component:str, # the component of the project grading, let it be proposal/checkpoint/final. Need to match the issue's title\n",
    "                    ) -> github.Issue.Issue:\n",
    "        \"Fetch the issue on GitHub repo and choose related one\"\n",
    "        for issue in list(repo.get_issues()):\n",
    "            if component in issue.title:\n",
    "                return issue\n",
    "        raise ValueError(f\"Issue related to {component} did not found.\")\n",
    "\n",
    "    def parse_score_from_issue(self,\n",
    "                               repo:github.Repository.Repository, # target repository to create issue\n",
    "                               component:str, # the component of the project grading, let it be proposal/checkpoint/final. Need to match the issue's title\n",
    "                               ) -> int: # the fetched score of that component\n",
    "        \"parse score from the template issue\"\n",
    "        issue = self.fetch_issue(repo, component)\n",
    "        body = issue.body\n",
    "        score = 0\n",
    "        for line in body.split(\"\\n\"):\n",
    "            if \"Score =\" in line and \"[comment]\" not in line:\n",
    "                score = literal_eval(line.split(\"=\")[1])\n",
    "                return score\n",
    "        raise ValueError(f\"Score Parse Error. please check the score format on github. \\n\"\n",
    "                         f\"Issue URL: {issue.url}\")\n",
    "\n",
    "    def update_canvas_score(self,\n",
    "                            group_name:str, # target group name on canvas group\n",
    "                            assignment_id, # assignment id of the related component\n",
    "                            score:float, # score of that component\n",
    "                            post=False, # whether to post score via api. for testing purposes\n",
    "                            ):\n",
    "        \"Post score to canvas\"\n",
    "        members = self.cg.group_to_emails[group_name]\n",
    "        self.cg.link_assignment(assignment_id)\n",
    "        for member in members:\n",
    "            student_id = self.cg.email_to_canvas_id[member]\n",
    "            if post:\n",
    "                self.cg.post_grade(\n",
    "                    student_id=student_id,\n",
    "                    grade=score,\n",
    "                    text_comment=f\"Group: {group_name}\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"{bcolors.WARNING}Post Disable{bcolors.ENDC}\")\n",
    "                print(f\"For student: {member}, the score is {score}\")\n",
    "\n",
    "    def grade_project(self,\n",
    "                      repo:github.Repository.Repository, # target repository to grade\n",
    "                      component:str, # the component of the project grading, let it be proposal/checkpoint/final. Need to match the issue's title\n",
    "                      assignment_id:int, # assignment id that link to that component of the project\n",
    "                      canvas_group_name=None, # mapping from GitHub repo name to Group name. If not specified, the repository name will be used.\n",
    "                      post=False, # whether to post score via api. For testing purposes\n",
    "                      ):\n",
    "        \"grade github project components\"\n",
    "        score = self.parse_score_from_issue(repo, component)\n",
    "        if canvas_group_name is not None:\n",
    "            group_name = canvas_group_name[repo.name]\n",
    "        else:\n",
    "            group_name = repo.name\n",
    "        self.update_canvas_score(group_name, assignment_id, score, post)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Grading.create_issue_from_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Grading.fetch_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Grading.parse_score_from_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Grading.update_canvas_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Grading.grade_project)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
